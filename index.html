<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Sheng Miao (苗升)</title>
    <meta name="author" content="Sheng Miao ">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:65%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sheng Miao (苗升)
                </p>
                <p><a href="https://www.zju.edu.cn/">Zhejiang University</a>. Hangzhou, PRC.</p>

                <p>I am currently pursuing my Ph.D. at Zhejiang University, under the guidance of <a href="https://yiyiliao.github.io/">Prof. Yiyi Liao</a>. 
                  Prior to this, I completed my Master's degree in Control Science and Engineering at Northwestern Polytechnical University (NWPU), advised by <a href="https://teacher.nwpu.edu.cn/liuxiaoxiong.html">Prof. Xiaoxiong Liu</a>.
                  I received the Bachelor's degree from NWPU in 2019.
                </p>
                <p>
                  Currently, I have focused on projects involving feed-forward techniques for 3D/4D scene reconstruction and 3D generation. I serve as the conference reviewer of CVPR and NIPS.
                </p>

                <p>
                  I am looking for a full-time job in the field of 3D/4D scene reconstruction and 3D generation. Feel free to contact me at <b>shengmiao@zju.edu.cn</b>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:shengmiao@zju.edu.cn">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://scholar.google.com/citations?hl=en&user=BPZQBTgAAAAJ">Scholar</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://twitter.com/jiaxinhuang2001">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/Miaosheng1">Github</a>
                </p>
              </td>
              <td style="padding:4.0%;width:50%;max-width:50%">
                <a href="images/avatar.jpg"><img style="width:80%;max-width:150%;object-fit: cover; border-radius: 5%;" alt="profile photo" src="images/avatar.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="text-indent:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
              </td>
            </tr>
          </tbody></table>

          <!-- <div style="height:80px;overflow-y:scroll;"> -->
          <div style="height:80px;overflow-y:scroll;">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <ul>
                <li>Jun 26, 2025: One paper is accepted to <b>ICCV 2025</b>.</li>
                <li>Feb 27, 2025: One paper is accepted to <b>CVPR 2025</b>.</li>
                <li>Jul 1, 2024: One paper is accepted to <b>ECCV 2024</b>.</li>
              </ul>
              </td>
            </tr>
            </tbody></table>
          </div>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected Publications</h2>
                <p>
                  * means equal contribution.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id="depth_model_image">
            <img src="images/depth_model.png" alt="Depth Model Image" width="100%" style="height:auto;">
          </div>
          <script type="text/javascript"> 
            function depth_model_start() {
              document.getElementById('depth_model_image').style.opacity = "1";
            }
  
            function depth_model_stop() {
              document.getElementById('depth_model_image').style.opacity = "0";
            }
          </script>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <span class="papertitle">Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation</span>
        <br>
        <a href="https://zhenx.me/">Zhen Xu</a><sup>∗</sup>,
        <a href="https://hyzhou404.github.io/">Hongyu Zhou</a><sup>∗</sup>,
        <a href="https://pengsida.net/">Sida Peng</a>,
        <a href="https://haotongl.github.io/">Haotong Lin</a>,
        <a href="https://jiahao-shao1.github.io/">Haoyu Guo</a>,
        <a href="https://jiahao-shao1.github.io/">Jiahao Shao</a>,
        Peishan Yang,
        Qinglin Yang,
        <strong>Sheng Miao</strong>,
        Xingyi He,
        Yifan Wang,
        Yue Wang,
        Ruizhen Hu,
        <a href="https://yiyiliao.github.io/">Yiyi Liao</a>,
        <a href="https://xzhou.me/">Xiaowei Zhou</a>,
        <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,
        <br>
        <em>Arxiv </em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2507.11540">Preprint</a>
        <br>
        <p>
          <em>
            This paper surveys the evolution of deep learning architectures and paradigms for depth estimation across the monocular, stereo, multi-view, and monocular video settings. We explore the potential of these models to address existing challenges and provide a comprehensive overview of large-scale datasets that can facilitate their development. 
          </em>
          
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
        <div class="two" id='vivid4d_image'><video width=100% height=76% muted autoplay loop>
        <source src="images/vivid4d_video.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video>
        <!-- </div>
          <img src='images/evolsplat_gif.gif' width="160">
        </div> -->
        <script type="text/javascript">
          function vivid4d_start() {
            document.getElementById('vivid4d_image').style.opacity = "1";
          }

          function vivid4d_stop() {
            document.getElementById('vivid4d_image').style.opacity = "0";
          }
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://xdimlab.github.io/Vivid4D/">
          <span class="papertitle">Vivid4D: Improving 4D Reconstruction from Monocular Video by Video Inpainting
    </span>
        </a>
        <br>
      <a href="https://jaceyhuang.github.io/">Jiaxin Huang</a>,
      <strong>Sheng Miao</strong>,
      <a href="https://ybbbbt.com/">Bangbang Yang</a>,
      Yuewen Ma,
      <a href="https://yiyiliao.github.io/">Yiyi Liao</a>,
        <br>
      <em>ICCV<em>, 2025
        <br>
        <a href="https://xdimlab.github.io/Vivid4D/">project page</a>
        /
        <a href="http://arxiv.org/abs/2504.11092">arXiv</a>
        <p></p>
        <p>
          A generative framework that addresses the challenge of reconstructing dynamic scenes from casual monocular videos with video diffusion model.
        </p>
      </td>
    </tr>          

    <tr onmouseout="evolsplat_stop()" onmouseover="evolsplat_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
        <div class="two" id='evolsplat_image'><video width=100% height=76% muted autoplay loop>
        <source src="images/evolsplat_video.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video>
        </div>
          <img src='images/evolsplat_gif.gif' width="160">
        </div>
        <script type="text/javascript">
          function evolsplat_start() {
            document.getElementById('evolsplat_image').style.opacity = "1";
          }

          function evolsplat_stop() {
            document.getElementById('evolsplat_image').style.opacity = "0";
          }
          evolsplat_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:top">
        <a href="https://xdimlab.github.io/EVolSplat/">
          <span class="papertitle">EVolSplat: Efficient Volume-based Gaussian Splatting for Urban View Synthesis
    </span>
        </a>
        <br>
      <strong>Sheng Miao</strong>,
      <a href="https://jaceyhuang.github.io/">Jiaxin Huang</a>,
      Dongfeng Bai,
      <a href="https://yanx27.github.io/">Xu Yan</a>,
      <a href="https://hyzhou404.github.io/"></a>Hongyu Zhou</a>,
      <a href="https://ywang-zju.github.io/">Yue Wang</a>,
      Bingbing Liu,
      <a href="https://www.cvlibs.net/">Andreas Geiger</a>,
      <a href="https://yiyiliao.github.io/">Yiyi Liao</a>,
        <br>
      <em>CVPR<em>, 2025
        <br>
        <a href="https://xdimlab.github.io/EVolSplat/">project page</a>
        /
        <a href="https://arxiv.org/abs/2503.20168">arXiv</a>
        <p></p>
        <p>
          A generalizable framework that predicts 3D Gaussians across multiple frames within a unified volume using convolutional networks.
        </p>
      </td>
    </tr>          

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
        <div class="two" id='edus_image'><video width=100% height=76% muted autoplay loop>
        <source src="images/edus_video.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video>
        <!-- </div>
          <img src='images/veri3d_image.jpg' width="160">
        </div> -->
        <script type="text/javascript">
          function edus_start() {
            document.getElementById('edus_image').style.opacity = "1";
          }

          function edus_stop() {
            document.getElementById('edus_image').style.opacity = "0";
          }
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://xdimlab.github.io/EDUS/">
          <span class="papertitle">Efficient Depth-Guided Urban View Synthesis
    </span>
        </a>
        <br>
      <strong>Sheng Miao</strong><sup>∗</sup>,
      <a href="https://jaceyhuang.github.io/">Jiaxin Huang</a><sup>∗</sup>,
      Dongfeng Bai,
      Weichao Qiu,
      Bingbing Liu,
      <a href="https://www.cvlibs.net/">Andreas Geiger</a>,
      <a href="https://yiyiliao.github.io/">Yiyi Liao</a>,
        <br>
      <em>ECCV<em>, 2024
        <br>
        <a href="https://xdimlab.github.io/EDUS/">project page</a>
        /
        <a href="https://arxiv.org/pdf/2407.12395">arXiv</a>
        <p></p>
        <p>
          A generalizable NeRF model that explicitly leverages geometric priors for feed-forward inference on unbounded sparse
          urban scenes.
        </p>
      </td>
    </tr>              
    
    
    <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id="edus_image">
          <img src="images/isprs.jpg" alt="ISPRS Image" width="100%" style="height:auto;">
        </div>
        <script type="text/javascript">
          function edus_start() {
            document.getElementById('edus_image').style.opacity = "1";
          }

          function edus_stop() {
            document.getElementById('edus_image').style.opacity = "0";
          }
        </script>
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <span class="papertitle">A Visual SLAM Robust against Dynamic Objects Based on Hybrid Semantic-Geometry Information</span>
      <br>
      <strong>Sheng Miao</strong>,
      Xiaoxiong Liu,
      Dazheng Wei,
      Changze Li,
      <br>
      <em>ISPRS International Journal of Geo-Information</em>, 2021, <strong>SCI Journal</strong>
      <br>
      <p>
        <em>
          A method for static/dynamic image segmentation that leverages semantic and geometric modules, including optical flow residual clustering, epipolar constraint checks, semantic segmentation to tackle dynamics.
        </em>
        
      </p>
    </td>
  </tr>



    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            &copy; 2025 Sheng Miao.
            Published with <a href="https://pages.github.com/" rel="nofollow">GitHub Pages</a>,
            powered by <a href="https://jonbarron.info/" rel="nofollow">Jon Barron</a>.
            Source code for this website can be found <a href="https://github.com/JaceyHuang/JaceyHuang.github.io/" rel="nofollow">here</a>.
          </p>
        </td>
      </tr>
    </tbody></table>

  </body>
</html>